{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all xml parsed .txt files into 1 corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set options\n",
    "pd.options.display.max_colwidth = 50\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine into one file using list comprehension\n",
    "##### files divided into multiple chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first chunk of files\n",
    "# 4 minutes to merge files,12 minutes to save file\n",
    "\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[0:5]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv \n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data1.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second chunk of files\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[5:8]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv\n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data2.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third chunk of files\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[8:10]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv\n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data3.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth chunk of files\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[10:13]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv\n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data4.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth chunk of files\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[13:15]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv\n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data5.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth chunk of files\n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/\") if x.endswith(\".txt\")]\n",
    "\n",
    "df_list = []\n",
    "for file in file_list[15:17]:\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/' + file, sep = '\\t'))\n",
    "\n",
    "big_df = pd.concat(df_list)\n",
    "\n",
    "# save file as .csv\n",
    "header = ['NAMEPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "big_df.to_csv('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data6.txt', sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 6 files txt into one big corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data1.txt',\n",
    "            '/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data2.txt',\n",
    "            '/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data3.txt',\n",
    "            '/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data4.txt',\n",
    "            '/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data5.txt',\n",
    "            '/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data6.txt']\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump_processed/revision_text_data_final.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
