{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Revision Diffs from Wikipedia XML dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2                                       # for decompression of files\n",
    "\n",
    "from mw import xml_dump                          # need to pip install mediawiki-utilities beforehand\n",
    "from mw.xml_dump import Iterator\n",
    "import difflib\n",
    "\n",
    "# set options\n",
    "pd.options.display.max_colwidth = 50\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "pd.options.mode.chained_assignment = None        # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Computing Diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diffs(orig_df):\n",
    "    transf_df = []\n",
    "    grouped_df = orig_df.groupby('PAGE_ID')                           # grouped data by page_id\n",
    "    for PAGE_ID,REVISION_ID in grouped_df:                                         \n",
    "        for i in range(1,len(REVISION_ID)):\n",
    "            revision1 = REVISION_ID.iloc[i-1,4]\n",
    "            revision2 = REVISION_ID.iloc[i,4]\n",
    "            revision1_split = revision1.splitlines(keepends=False)\n",
    "            revision2_split = revision2.splitlines(keepends=False)\n",
    "            diff = difflib.Differ()                                   # initiate the differ object\n",
    "            result = diff.compare(revision1_split,revision2_split)    # calculate difference\n",
    "            diff_text = []\n",
    "            for line in result:\n",
    "                if line.startswith(\"+\"):                              # + means unique to second object\n",
    "                    diff_text.append(line)                            # if unique to second object; keep in second only\n",
    "                else:\n",
    "                    pass                                              # do nothing \n",
    "            diff_text_val = \" \".join(diff_text)                       # convert list object to string\n",
    "            REVISION_ID.iloc[i,7] = diff_text_val                     # dump val to DIFF_TEXT column\n",
    "            transf_df.append({'CONTRIBUTOR':REVISION_ID.iloc[i-1,0],\n",
    "                              'NAMESPACE':REVISION_ID.iloc[i-1,1],\n",
    "                              'PAGE_ID':REVISION_ID.iloc[i-1,2],\n",
    "                              'REVISION_ID':REVISION_ID.iloc[i-1,3],\n",
    "                              'TEXT':REVISION_ID.iloc[i-1,4],\n",
    "                              'TIMESTAMP':REVISION_ID.iloc[i-1,5],\n",
    "                              'TITLE':REVISION_ID.iloc[i-1,6],\n",
    "                              'DIFF_TEXT':REVISION_ID.iloc[i-1,7]})\n",
    "    transf_df = pd.DataFrame(transf_df)                              \n",
    "    transf_df = transf_df[['NAMESPACE','CONTRIBUTOR','TITLE',        # rearrange order of columns\n",
    "                           'PAGE_ID','REVISION_ID','TIMESTAMP',\n",
    "                           'TEXT','DIFF_TEXT']]                      \n",
    "    return transf_df                                                 # return transformed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Parse XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_parse(xml_compressed_file):\n",
    "    dump = Iterator.from_file(bz2.BZ2File(xml_compressed_file))\n",
    "    df = []\n",
    "    # Iterate through pages\n",
    "    for page in dump:\n",
    "        [df.append({'PAGE_ID':page.id,'NAMEPSACE':page.namespace,\n",
    "                       'TITLE':page.title,'REVISION_ID':revision.id,\n",
    "                       'TIMESTAMP':revision.timestamp,'CONTRIBUTOR':revision.contributor,\n",
    "                       'TEXT':revision.text}) for revision in page if page.namespace in (1,3)]\n",
    "\n",
    "    wiki_df = pd.DataFrame(df)       \n",
    "    wiki_df.insert(7, 'DIFF_TEXT', '')                                        # add empty column for diff_text\n",
    "    wiki_df['TEXT'].replace('\\.\\s?(?![a-z])','.\\n',regex=True,inplace=True)   # add linebreak after fullstop\n",
    "    wiki_df['TEXT'].replace(\"\\[\\[.*\\]\\]?\",\"\",regex=True,inplace=True)         # replace [[wordherelinkedbywiki]] \n",
    "    wiki_df['TEXT'].replace('\\n+','\\n',regex=True,inplace=True)               # replace multilinebreaks with one linebreak\n",
    "\n",
    "    wiki_df_diff = compute_diffs(wiki_df)                                     # call to function compute_diffs()\n",
    "    \n",
    "    #dump txt files\n",
    "    header = ['NAMESPACE','CONTRIBUTOR','TITLE','PAGE_ID','REVISION_ID','TIMESTAMP','TEXT','DIFF_TEXT']\n",
    "    wiki_df_diff.to_csv(str(xml_compressed_file)[:-4] + \".txt\", sep = '\\t',encoding='utf-8',header = True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform operation on the XML dump - all files in directory\n",
    "For every XML file in the folder, parse and dump a .CSV in the folder with the diff for every text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump/\"                             \n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump/\") \n",
    "             if x.endswith(\".bz2\") ]                                                \n",
    "\n",
    "for file in file_list[-20:-18]: # specific files\n",
    "    xml_compressed_file = str(path) + str(file)     \n",
    "    print(xml_compressed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list[-20:-18]:\n",
    "    xml_compressed_file = str(path) + str(file)     # file to be parsed\n",
    "    xml_parse(xml_compressed_file)                  # call to function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform operation on one specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single file\n",
    "path = \"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump/\"                             \n",
    "file_list = [x for x in os.listdir(\"/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump/\") \n",
    "             if x.endswith(\".bz2\") ]                                            \n",
    "\n",
    "xml_compressed_file = str(path) + str(file_list[-22]) # one specific file\n",
    "print(xml_compressed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single file\n",
    "xml_parse(xml_compressed_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run trial to check diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = Iterator.from_file(bz2.BZ2File('/home/ec2-user/SageMaker/s3fs-fuse/bucket/wiki_trust/xml_dump/enwiki-20180901-pages-meta-history1.xml-p16229p18132.bz2'))\n",
    "df = []\n",
    "# Iterate through pages\n",
    "for page in dump:\n",
    "    [df.append({'PAGE_ID':page.id,'NAMEPSACE':page.namespace,\n",
    "                'TITLE':page.title,'REVISION_ID':revision.id,\n",
    "                'TIMESTAMP':revision.timestamp,'CONTRIBUTOR':revision.contributor,\n",
    "                'TEXT':revision.text}) for revision in page if page.namespace in (1,3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.DataFrame(df)\n",
    "wiki_df = wiki_df.head(30)\n",
    "wiki_df.insert(7, 'DIFF_TEXT', '')  \n",
    "wiki_df['TEXT'].replace('\\.\\s?(?![a-z])','.\\n',regex=True,inplace=True) # add linebreak after fullstop\n",
    "wiki_df['TEXT'].replace(\"\\[\\[.*\\]\\]?\",\"\",regex=True,inplace=True) # replace [[ericross]] not [[Wiki:China]]\n",
    "wiki_df['TEXT'].replace('\\n+','\\n',regex=True,inplace=True) # replace multilinebreaks with one linebreak\n",
    "#wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df_diff = compute_diffs(wiki_df)\n",
    "wiki_df_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision1 = wiki_df_diff.iloc[0,6]\n",
    "revision2 = wiki_df_diff.iloc[1,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(revision1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(revision2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision1_split = revision1.splitlines(keepends=False)\n",
    "revision2_split = revision2.splitlines(keepends=False)\n",
    "diff = difflib.Differ()                             \n",
    "result = diff.compare(revision1_split,revision2_split)    \n",
    "diff_text = []\n",
    "for line in result:\n",
    "    if line.startswith(\"+\"):                             \n",
    "        diff_text.append(line)                            \n",
    "    else:\n",
    "        pass                                              \n",
    "    diff_text_val = \" \".join(diff_text)\n",
    "diff_text_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(revision1_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(revision2_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
