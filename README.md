# Wikipedia - Trust & Safety
### Online Harassment Detection and Early Prediction of Problematic Users in the English Wikipedia Community

#### Team - Charu Rawat ,Arnab Sarkar and Sameer Singh

#### This repo contains code part of our capstone project on leveraging machine learning and deep learning techniques to detect online harassment in the Wikipedia user community. This project is a part of the UVA MS Data Science Program and is sponsored by the Wikimedia Foundation. The project is expected to be completed by May 2019.

Please click [here](https://meta.wikimedia.org/wiki/University_of_Virginia/Machine_learning_to_predict_Wikimedia_user_blocks) to read more about the research project.

#### Project description:
The advent of the Internet can be easily heralded as one of the key events which
led to the “Information age” as it is colloquially known. Sharing of thoughts, ideas and opinions
reached new heights when people were able to engage in meaningful debates through online forums.
However, a darker aspect to this medium – online harassment, has become became rampant in these
communities. The Wikipedia user community is no stranger to this phenomenon. As of January 2019,
Wikipedia has 35 million users and on average 250k users register every month. Also, as per the
Wikipedia Community Engagement Insights 2018 report - 68% of the respondents reported having
experienced harassment at some point in the past and as a result about 22% of Wikipedians reported a
decrease in their contribution levels. To combat harassment, currently Wikipedia has an organic,
human-driven process in place, where cases of abuse reported are evaluated and enacted upon by
Wikipedia administrators. But relying on human evaluation works in some ways but it is not a solution
which scales with the growth of Wikipedia, as there were ~170k user blocks in 2018 alone.

Our goal is to develop a data-driven approach in combating cyber harassment that will address a
variety of issues that are otherwise faced by the human driven process, from errors and bias in human
judgement to efficiently evaluating a larger magnitude of cases. By analyzing user activity in form of
editing behavior and discussions, we will be able to predict users who are at risk of getting blocked in
the future.
